{"version":3,"file":"component---src-pages-technicalanimation-js-a108dadfd648b35a7f98.js","mappings":"uKAsPA,UAhP2B,WACzB,OACE,2BACE,gBAAC,IAAM,KACL,wBAAMA,IAAI,OAAOC,KAAK,YAAYC,KAAMC,EAAAA,IACxC,uEAEF,uBAAKC,UAAWC,EAAAA,IACd,gBAAC,IAAS,MACV,uBAAKD,UAAWE,EAAAA,IACd,6DACA,oDACA,+WASA,oDACA,uaASA,oDACA,0ZASA,oDACA,k+BAkBA,oDACA,o8BAkBA,oDACA,8rBAcA,oDACA,goBAaA,qDACA,qbAUA,qDACA,8ZASA,qDACA,wfAWA,qDACA,2bAQE,qBAAGJ,KAAK,uCAAqC,oDAEzC,mFAKN,qDACA,gsBAcA,iDACA,w3BAgBA,kDACA,6uBAYE,qBAAGA,KAAK,sEACL,IAAG,qCAED,IAAG,KACL,IACH,qBAAGA,KAAK,sEACL,IAAG,mBAED,IAAG,sOAOV,kDACA,25BAoBV,C,gRCnPO,IAAIK,EAAS,mCACTC,EAAe,yCACfC,EAAc,wCACdC,EAAU,oCACVJ,EAAW,qCACXK,EAAc,wCACdC,EAAS,mCACTP,EAAU,oCACVQ,EAAc,wCACdC,EAAQ,iC","sources":["webpack://ashley-kim/./src/pages/technicalanimation.js","webpack://ashley-kim/./src/pages/ResumePage.module.css"],"sourcesContent":["import React from \"react\";\nimport AppHeader from \"../component/AppHeader/AppHeader\";\nimport favicon from \"../images/favicon.png\";\nimport { Helmet } from \"react-helmet\";\nimport { overall, content2 } from \"./ResumePage.module.css\";\n\nconst technicalanimation = () => {\n  return (\n    <div>\n      <Helmet>\n        <link rel=\"icon\" type=\"image/png\" href={favicon} />\n        <title>Ashley Kim | Technical Animation Blog</title>\n      </Helmet>\n      <div className={overall}>\n        <AppHeader />\n        <div className={content2}>\n          <h1>15-464 Technical Animation Blog</h1>\n          <h2>January 18, 2023 (Wed)</h2>\n          <p>\n            I'm excited for this class, especially for the special effects\n            aspect of the course. My main interest lies in special effects,\n            interactive design, and immersive media. I look forward to learning\n            more about the state of art technical animation tools and algorithms\n            and potentially apply or use those tools in my personal\n            practice/projects.\n          </p>\n\n          <h2>January 23, 2023 (Mon)</h2>\n          <p>\n            Going over walk cycle and motion capture was a good review for me,\n            as the last time I worked with these was last spring semester (S22).\n            Although I've seen many of the applications of motion capture data,\n            I haven't really looked into the data file itself before. Looking\n            into what the motion capture data file looks like made me appreciate\n            once again of the already developed opensource parsers.\n          </p>\n\n          <h2>January 25, 2023 (Wed)</h2>\n          <p>\n            Learning about different implementation methods for IK in class\n            today was highly valuable to me. All I knew regarding Jacobian was\n            the basics that we briefly covered in Computer Graphics course, so\n            walking through the paper on different applications of Jacobian and\n            pseudoinverse was very helpful. Perhaps I can try implementing these\n            for the second part of the first mini project?\n          </p>\n\n          <h2>January 30, 2023 (Mon)</h2>\n          <p>\n            It was interesting to see how Jacobian transpose relates to gradient\n            descent. However, I don't know if I fully understand the transition\n            from the equation we covered last class to the one we covered today,\n            as I don't see how subtracting the offset gives similar result. Or\n            was it suppose to mean that the gradient descent gives higher\n            accuracy because it's subtracting the offset amount of a part that\n            shouldn't be shifting? I also realized during today's class that I\n            was misunderstanding the use of rotational axis in last class when\n            it's used to cross with the distance from joint to end point (r_i).\n            I appreciate how material we cover in class build onto each other\n            instead of introducing new topic each time. This way gives me time\n            to sit with the topic we covered in class and review again during\n            the following class to strengthen understanding. Also, it\n            assimiliates how researches are done (i.e. build onto previously\n            released paper and compare & contrast).\n          </p>\n\n          <h2>February 1, 2023 (Wed)</h2>\n          <p>\n            To me, rigging and skinning always have been the 'required' steps\n            that I just had to do to get to the fun animation part. Learning\n            about RigNet and Neural Blend Shapes for rigging and skinning was\n            useful, as it seemed highly practical and time-saving. I still\n            wonder how these models were trained, specifically how blend shapes\n            are predicted. Based on my previous experience, blend shapes still\n            rely on the initial rigging and skinning that's done on the rest A\n            or T pose of the character, then set a certain pose as the end pose\n            for the blend shape. However, the Neural Blend Shapes paper seemed\n            to imply that these blend shapes can be trainned in a different\n            manner than how RigNet trains to predict where the rig would be\n            located and mesh weights would be distributed. Although my main\n            interest lies in visual effects and simulation, I think it would be\n            interesting to further look into the papers on automated rigging and\n            skinning.\n          </p>\n\n          <h2>February 6, 2023 (Mon)</h2>\n          <p>\n            Motion capture lab visit was a good review session, although since\n            it was my third time there as a class, I wasn't surprised with\n            anything new. I'm still unclear if I would use motion capture lab\n            for the final project, but I'm glad to know that it's available as\n            an option if I need to capture any motion. Learning about Arjun's\n            paper on figuring out the hand gesture by area indication on mesh\n            was highly interesting, as I haven't thought about defining a hand\n            gesture based on a contact area between the two mesh. I think in\n            general learning about what techniques are out there opens up the\n            perspective on how one can see the same problem form different\n            angles and focus.\n          </p>\n\n          <h2>February 8, 2023 (Wed)</h2>\n          <p>\n            First paper presentations today. Again, I find these paper\n            presentations really crucial and useful, as I get to have exposures\n            to various techniques out there without having to fully dive into\n            the paper and all the math. The non-Euclidean space paper was highly\n            interesting, as I've seen its applications across various video\n            games but didn't really know much about the concept and math behind\n            it. I also wouldn't have known about it since I couldn't tell that\n            the paper discussed such a topic only from the title. (i.e. I didn't\n            know such portal effect and dimension changing was called\n            non-Euclidean space...)\n          </p>\n\n          <h2>February 13, 2023 (Mon)</h2>\n          <p>\n            As also an art student, I think having a time dedicated for sharing\n            works is useful for future projects. Although it wasn't a crit\n            session for people to give ideas on how to improve on the project,\n            viewing others' works gave me a good sense of what the individual\n            strengths of this class is. It was also a session that reminded me\n            of how the artists and the developers view and operate the tools\n            differently.\n          </p>\n\n          <h2>February 15, 2023 (Wed)</h2>\n          <p>\n            I don't think I ever looked into how cloth simulation works behind\n            the scene. It was quiet a fresh idea for me to see that the cloth\n            simulation is a collection of spring phyiscs intertwined. I see how\n            this would intuitively work since cloth also has a tendancy to go\n            back to its original stable state upon stretching it out. I wonder\n            who first came up with this idea to simulate cloth.\n          </p>\n\n          <h2>February 20, 2023 (Mon)</h2>\n          <p>\n            I think cloth collision is one of the effects/simulations that can\n            convey so many different types by just tweeking a few paramenters.\n            There exits so many types and feels of fabric in this world, and I\n            think that's what makes cloth simulation both the hardest and the\n            easiest to make. As long as we make sure the cloth doesn't get\n            caught in the movement of the rig and creates an artifact, cloth\n            simulation can already look somewhat natural enough to convey the\n            idea of cloth.\n          </p>\n\n          <h2>February 22, 2023 (Wed)</h2>\n          <p>\n            Talking about different ways of collision offset/detection methods\n            reminded me of Computer Graphics light ray and particle collision\n            parts. Since we already went over and had to implement as part of\n            the Computer Graphics course, checking whether collision has\n            occurred and going forward/back in the timestep to place the object\n            at the boarder was the most straightforward idea to understand. I\n            also happened to make\n            <a href=\"https://www.instagram.com/kitetale/\">\n              a few of rigid-body collision effects in Houdini\n            </a>\n            , and I was very surprised by how accurate Houdini's code dealt with\n            collision.\n          </p>\n\n          <h2>February 27, 2023 (Mon)</h2>\n          <p>\n            Among the papers presented today, I found the cloth prediction one\n            very interesting. I learned so much through this class that Neural\n            Network has been the state of the art method for various types of\n            simulations and animation techniques. It really reminded me of how\n            AI is integrating into all industries to improve the techniques.\n            Yarn-level cloth simulation was also cool to learn about, as I\n            haven't really thought about how different patterns of weaving\n            influence how the overall cloth interacts with itself and other\n            objects. I'm not sure if it's a trend in CMU or everywhere, but I\n            also have noticed that a lot more people are now interested in the\n            algorithmic textile.\n          </p>\n\n          <h2>March 1, 2023 (Wed)</h2>\n          <p>\n            Seeing previous final projects today was so intriguing and\n            inspiring. I was not only able to understand what's expected for the\n            final project, but also guage the diversity in topics and methods\n            that I could implement for the final project. I think I want to do\n            some sort of particle simulation, probably particle simulation that\n            mimics fluid simulation. The water ripple one and rigid body contact\n            seemed very fun to play with and relatively easy to implement. Snow\n            simulation was also interesting -- I remember seeing snow simulation\n            test videos for Frozen from Art, Animation, and Technology class.\n            Perhaps I could do a wrecking ball/angry bird collision on snow-like\n            particles. I'm still not sure what I would be working on for the\n            final project, so my plan would be coming up with several ideas and\n            narrow it down to one during the meeting with professor.\n          </p>\n\n          <h2>March 13, 2023 (Mon)</h2>\n          <p>\n            I just flew in from Ithaca this morning and came straight to the\n            class. I thought I'd be missing this class, but I was able to find\n            an alternative flight that would let me be here in time for class!\n            I'm excited for my final project; I was afraid the idea I liked the\n            most (applying real-time Kinect depth mocap data to the character\n            like what Nick did before) might be out of scope for the class, but\n            I'm glad to have the professor's confirmation that it's within the\n            scope. I may have to flesh out my idea more, but I'm planning to use\n            openFrameworks to apply mocap data from Kinect's depth image to a 3d\n            character. Perhaps I can use GLSL to make the 3D character? I was\n            extremely impressed when I watched Inigo Quilez's\n            <a href=\"https://www.youtube.com/watch?v=8--5LwHRhjk&ab_channel=InigoQuilez\">\n              {\" \"}\n              \"Painting a Character with Maths\"\n            </a>{\" \"}\n            or{\" \"}\n            <a href=\"https://www.youtube.com/watch?v=Cfe5UQ-1L9Q&ab_channel=InigoQuilez\">\n              {\" \"}\n              \"Happy Jumping\"\n            </a>{\" \"}\n            animation live coding video. Perhaps I could pull some math\n            equations from these to construct my own ( simpler) character for\n            the final project. I'm thinking to have both live demo and\n            documentation video for the presentation.\n          </p>\n\n          <h2>March 15, 2023 (Wed)</h2>\n          <p>\n            Although I have decided to work with Kinect for my final project,\n            hearing about others' final project ideas and references was quiet \n            inspiring and useful. I'm planning to read more about certain papers\n            others mentioned, such as rigid body fracture based on pressure, for\n            my senior art capstone project that I'll be presenting at the senior\n            art show at Miller ICA at the end of the semester. \n            Otherwise, I'm excited to learn more about fluid simulation. It's \n            just so mindblowing to see how much graphcis technology has developed\n            over time -- Water simulation in Avater II was extremely realistic,\n            and it's always impressive to see and realize that the first 'good-looking'\n            fluid simulations only happened not so long ago. Sometimes I feel like\n            the world has invented so many algorithms and graphical techniques \n            while I was just growing up... So much has happened since 2000, if not \n            even before.\n          </p>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default technicalanimation;\n","// extracted by mini-css-extract-plugin\nexport var center = \"ResumePage-module--center--9b0dd\";\nexport var centerButton = \"ResumePage-module--centerButton--df016\";\nexport var centerTitle = \"ResumePage-module--centerTitle--bbb03\";\nexport var content = \"ResumePage-module--content--dfefc\";\nexport var content2 = \"ResumePage-module--content2--e4fd6\";\nexport var footDescrip = \"ResumePage-module--footDescrip--5a6f4\";\nexport var footer = \"ResumePage-module--footer--ef519\";\nexport var overall = \"ResumePage-module--overall--a999b\";\nexport var resumeStyle = \"ResumePage-module--resumeStyle--64bc2\";\nexport var title = \"ResumePage-module--title--acc5f\";\nexport var title3 = \"ResumePage-module--title3--2ba8f\";"],"names":["rel","type","href","favicon","className","overall","content2","center","centerButton","centerTitle","content","footDescrip","footer","resumeStyle","title"],"sourceRoot":""}