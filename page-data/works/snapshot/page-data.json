{"componentChunkName":"component---src-pages-works-mdx-slug-js","path":"/works/snapshot/","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Snapshot\",\n  \"description\": \"Snapshot is a Kinect-based project that displays a composite image of what was captured over time through depth.\",\n  \"title_color\": \"#565252\",\n  \"hero_img\": \"../src/images/snapshot/snapshot_hero.png\",\n  \"hero_img_alt\": \"One output of snapshot taken in a bedroom\",\n  \"hero_img_description\": \"Snapshot Example\",\n  \"local_imgs\": [\"../src/images/snapshot/snapshot.png\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"div\", {\n    className: infogrid\n  }, mdx(\"div\", {\n    className: overview\n  }, mdx(\"div\", null, mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Overview\"))), mdx(\"div\", {\n    className: closerLineHeight\n  }, \"Snapshot is a Kinect-based project that displays a composite image of what was captured over time through depth. Each layer that builds up the image contains the outline of objects captured at different depth range at different time. The layers are organized by time: The oldest capture is at the background and the newest capture is at the foreground.\")), mdx(\"div\", {\n    className: infos\n  }, mdx(\"div\", {\n    className: info\n  }, mdx(\"div\", null, mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Duration \"))), mdx(\"div\", {\n    className: closerLineHeight\n  }, \"Nov 22 - Dec 6,2022 \", mdx(\"br\", null), \" (2 weeks)\")), mdx(\"div\", {\n    className: info\n  }, mdx(\"div\", null, mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tool \"))), mdx(\"div\", {\n    className: closerLineHeight\n  }, \"openFrameworks \", mdx(\"br\", null), \" Kinect \", mdx(\"br\", null), \" Thermal Printer\")))), mdx(\"div\", {\n    className: subTitle\n  }, \"Inspiration\"), mdx(\"div\", {\n    style: {\n      \"marginBottom\": \"3rem\"\n    }\n  }, \"Extending the from \", mdx(\"i\", null, \"Travel Over Time\"), \" project, I wanted to further find a way to capture a location over time. Depending on the time of the day, the same location may be empty or extremely crowded. Sometimes an unexpected passes by the location, but it would be only seen at that specific time. Wondering what the output would look like if each depth layer is the capture of the same location from different point of time, I developed a program that separately saves the kinect input image by depth range and compiles randomly selected images per layer from the past in a chronological order.\"), mdx(\"div\", {\n    className: subTitle\n  }, \"Process\"), mdx(\"div\", {\n    className: infos,\n    style: {\n      \"padding\": \"0\"\n    }\n  }, mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"width\": \"80%\"\n    }\n  }, \"I first used Kinect to get the depth data of the scene \\u2192\"), mdx(\"img\", {\n    style: {\n      \"width\": \"100%\"\n    },\n    src: depthCam,\n    alt: \"depth data image from Kinect camera\"\n  })), mdx(\"div\", {\n    className: infos,\n    style: {\n      \"padding\": \"0\"\n    }\n  }, mdx(\"img\", {\n    style: {\n      \"width\": \"100%\"\n    },\n    src: pointCloud,\n    alt: \"point cloud created from depth data obtained from Kinect camera\"\n  }), mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"width\": \"80%\"\n    }\n  }, \" \\u2190 Then I created point cloud with the depth information as z \")), mdx(\"div\", {\n    className: infos,\n    style: {\n      \"padding\": \"0\"\n    }\n  }, mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"width\": \"80%\"\n    }\n  }, \"I then divided the points into 6 buckets based on their depth range with HSB color value, which is also based on depth \\u2192\"), mdx(\"img\", {\n    style: {\n      \"width\": \"100%\"\n    },\n    src: depthInfo,\n    alt: \"point cloud points divided into 6 buckets, sorted by color\"\n  })), mdx(\"div\", {\n    className: infos,\n    style: {\n      \"padding\": \"0\"\n    }\n  }, mdx(\"img\", {\n    style: {\n      \"width\": \"100%\"\n    },\n    src: buckets,\n    alt: \"point cloud points above put into triangular mesh by connecting adjacent three points\"\n  }), mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"width\": \"80%\"\n    }\n  }, \" \\u2190 I also created triangular mesh out of points per bucket \")), mdx(\"div\", {\n    className: infos,\n    style: {\n      \"padding\": \"0\"\n    }\n  }, mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"width\": \"80%\"\n    }\n  }, \"I wrote a function that would automatically save the data per layer every certain time interval (e.g. every minute, every 10 seconds, etc.)\", mdx(\"p\", null, \"These are different views of Kinect \", \"\\u2192\"), mdx(\"p\", null, \"(Starting with top left and clock-wise: depth data, RGB data, object outlines, compiled depth buckets in grayscale, individual bucket in grayscale)\")), mdx(\"img\", {\n    style: {\n      \"width\": \"100%\"\n    },\n    src: allViews,\n    alt: \"different views and data obtained from Kinect camera. Starting with top left and clock-wise: depth data, RGB data (normal camera), object outlines, compiled depth buckets in grayscale, individual bucket in grayscale.\"\n  })), mdx(\"div\", {\n    className: subTitle,\n    style: {\n      \"marginTop\": \"3rem\"\n    }\n  }, \"How It works\"), mdx(\"div\", {\n    style: {\n      \"marginBottom\": \"3rem\"\n    }\n  }, \"Upon pressing a button to capture, the program generates 6 random numbers and sorts them in order to pull captured layers in chronological order. It then combines the layers all together by taking the biggest pixel value across 6 layer images. Once the image is constructed, it frames in a polaroid template with location and timeframe (also saved and retrieved in the same manner as the layers) below the image.\"), mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"justifyContent\": \"center\",\n      \"display\": \"flex\"\n    }\n  }, mdx(\"img\", {\n    style: {\n      \"width\": \"40%\",\n      \"boxShadow\": \"0 10px 16px 0 rgb(0 0 0 / 20%), 0 6px 20px 0 rgb(0 0 0 / 19%)\"\n    },\n    src: final,\n    alt: \"Example snapshot outputs.\"\n  })), mdx(\"div\", {\n    className: subTitle,\n    style: {\n      \"marginTop\": \"3rem\"\n    }\n  }, \"Exhibition Installation\"), mdx(\"div\", {\n    style: {\n      \"margin\": \"auto\",\n      \"display\": \"flex\",\n      \"flexDirection\": \"row\",\n      \"flexWrap\": \"wrap\",\n      \"justifyContent\": \"center\"\n    }\n  }, mdx(\"img\", {\n    style: {\n      \"width\": \"40%\",\n      \"boxShadow\": \"0 10px 16px 0 rgb(0 0 0 / 20%), 0 6px 20px 0 rgb(0 0 0 / 19%)\",\n      \"marginRight\": \"1rem\",\n      \"marginBottom\": \"1rem\"\n    },\n    src: exhibition1,\n    alt: \"Exhibition of Snapshot at The STUDIO for Creative Inquiry.\"\n  }), mdx(\"img\", {\n    style: {\n      \"width\": \"40%\",\n      \"boxShadow\": \"0 10px 16px 0 rgb(0 0 0 / 20%), 0 6px 20px 0 rgb(0 0 0 / 19%)\",\n      \"marginRight\": \"1rem\",\n      \"marginBottom\": \"1rem\"\n    },\n    src: exhibition4,\n    alt: \"Exhibition of Snapshot at The STUDIO for Creative Inquiry.\"\n  }), mdx(\"img\", {\n    style: {\n      \"width\": \"40%\",\n      \"boxShadow\": \"0 10px 16px 0 rgb(0 0 0 / 20%), 0 6px 20px 0 rgb(0 0 0 / 19%)\",\n      \"marginRight\": \"1rem\",\n      \"marginBottom\": \"1rem\"\n    },\n    src: exhibition2,\n    alt: \"Exhibition of Snapshot at The STUDIO for Creative Inquiry.\"\n  }), mdx(\"img\", {\n    style: {\n      \"width\": \"40%\",\n      \"boxShadow\": \"0 10px 16px 0 rgb(0 0 0 / 20%), 0 6px 20px 0 rgb(0 0 0 / 19%)\",\n      \"marginRight\": \"1rem\",\n      \"marginBottom\": \"1rem\"\n    },\n    src: exhibition3,\n    alt: \"Exhibition of Snapshot at The STUDIO for Creative Inquiry.\"\n  })));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"description":"Snapshot is a Kinect-based project that displays a composite image of what was captured over time through depth.","hero_img":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3c755e2a991252b4cddc732b55882994/7ddbe/snapshot_hero.png","srcSet":"/static/3c755e2a991252b4cddc732b55882994/f2db2/snapshot_hero.png 158w,\n/static/3c755e2a991252b4cddc732b55882994/52d9d/snapshot_hero.png 315w,\n/static/3c755e2a991252b4cddc732b55882994/7ddbe/snapshot_hero.png 630w","sizes":"(min-width: 630px) 630px, 100vw"},"sources":[{"srcSet":"/static/3c755e2a991252b4cddc732b55882994/b816e/snapshot_hero.webp 158w,\n/static/3c755e2a991252b4cddc732b55882994/fecf0/snapshot_hero.webp 315w,\n/static/3c755e2a991252b4cddc732b55882994/b7c7d/snapshot_hero.webp 630w","type":"image/webp","sizes":"(min-width: 630px) 630px, 100vw"}]},"width":630,"height":480}}},"hero_img_alt":"One output of snapshot taken in a bedroom","hero_img_description":"Snapshot Example","title":"Snapshot","title_color":"#565252","local_imgs":[{"childrenImageSharp":[{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/d90d8951b2b30bfc7c9c8e0315e28afc/829ac/snapshot.png","srcSet":"/static/d90d8951b2b30bfc7c9c8e0315e28afc/bfe6d/snapshot.png 188w,\n/static/d90d8951b2b30bfc7c9c8e0315e28afc/900b3/snapshot.png 375w,\n/static/d90d8951b2b30bfc7c9c8e0315e28afc/829ac/snapshot.png 750w","sizes":"(min-width: 750px) 750px, 100vw"},"sources":[{"srcSet":"/static/d90d8951b2b30bfc7c9c8e0315e28afc/293d8/snapshot.webp 188w,\n/static/d90d8951b2b30bfc7c9c8e0315e28afc/4184f/snapshot.webp 375w,\n/static/d90d8951b2b30bfc7c9c8e0315e28afc/02c63/snapshot.webp 750w","type":"image/webp","sizes":"(min-width: 750px) 750px, 100vw"}]},"width":750,"height":768}}]}]}}},"pageContext":{"id":"42472500-e4cf-5015-bff7-fcedf623808f","slug":"snapshot","__params":{"slug":"snapshot"}}},"staticQueryHashes":[]}