{"version":3,"file":"component---src-pages-technicalanimation-js-547e11d5c90119ca713c.js","mappings":"uKA4TA,UAtT2B,WACzB,OACE,2BACE,gBAAC,IAAM,KACL,wBAAMA,IAAI,OAAOC,KAAK,YAAYC,KAAMC,EAAAA,IACxC,uEAEF,uBAAKC,UAAWC,EAAAA,IACd,gBAAC,IAAS,MACV,uBAAKD,UAAWE,EAAAA,IACd,6DACA,oDACA,+WASA,oDACA,uaASA,oDACA,0ZASA,oDACA,k+BAkBA,oDACA,o8BAkBA,oDACA,8rBAcA,oDACA,goBAaA,qDACA,qbAUA,qDACA,8ZASA,qDACA,wfAWA,qDACA,2bAQE,qBAAGJ,KAAK,uCAAqC,oDAEzC,mFAKN,qDACA,gsBAcA,iDACA,w3BAgBA,kDACA,6uBAYE,qBAAGA,KAAK,sEACL,IAAG,qCAED,IAAG,KACL,IACH,qBAAGA,KAAK,sEACL,IAAG,mBAED,IAAG,sOAOV,kDACA,y5BAiBA,kDACA,0cAIA,kDACA,ujBAIA,kDACA,yaAIA,kDACA,gnBAWA,iDACA,qeAQA,iDACA,+lBAWA,kDACA,mTAC2R,qBAAGA,KAAK,8BAA4B,SAAU,2VAEzU,kDACA,kEAC0C,qBAAGA,KAAK,gDAA8C,uBAAwB,+wBAGxH,kDACA,mhBAIA,kDACA,8vBAUV,C,gRCzTO,IAAIK,EAAS,mCACTC,EAAe,yCACfC,EAAc,wCACdC,EAAU,oCACVJ,EAAW,qCACXK,EAAc,wCACdC,EAAS,mCACTP,EAAU,oCACVQ,EAAc,wCACdC,EAAQ,iC","sources":["webpack://ashley-kim/./src/pages/technicalanimation.js","webpack://ashley-kim/./src/pages/ResumePage.module.css"],"sourcesContent":["import React from \"react\";\nimport AppHeader from \"../component/AppHeader/AppHeader\";\nimport favicon from \"../images/favicon.png\";\nimport { Helmet } from \"react-helmet\";\nimport { overall, content2 } from \"./ResumePage.module.css\";\n\nconst technicalanimation = () => {\n  return (\n    <div>\n      <Helmet>\n        <link rel=\"icon\" type=\"image/png\" href={favicon} />\n        <title>Ashley Kim | Technical Animation Blog</title>\n      </Helmet>\n      <div className={overall}>\n        <AppHeader />\n        <div className={content2}>\n          <h1>15-464 Technical Animation Blog</h1>\n          <h2>January 18, 2023 (Wed)</h2>\n          <p>\n            I'm excited for this class, especially for the special effects\n            aspect of the course. My main interest lies in special effects,\n            interactive design, and immersive media. I look forward to learning\n            more about the state of art technical animation tools and algorithms\n            and potentially apply or use those tools in my personal\n            practice/projects.\n          </p>\n\n          <h2>January 23, 2023 (Mon)</h2>\n          <p>\n            Going over walk cycle and motion capture was a good review for me,\n            as the last time I worked with these was last spring semester (S22).\n            Although I've seen many of the applications of motion capture data,\n            I haven't really looked into the data file itself before. Looking\n            into what the motion capture data file looks like made me appreciate\n            once again of the already developed opensource parsers.\n          </p>\n\n          <h2>January 25, 2023 (Wed)</h2>\n          <p>\n            Learning about different implementation methods for IK in class\n            today was highly valuable to me. All I knew regarding Jacobian was\n            the basics that we briefly covered in Computer Graphics course, so\n            walking through the paper on different applications of Jacobian and\n            pseudoinverse was very helpful. Perhaps I can try implementing these\n            for the second part of the first mini project?\n          </p>\n\n          <h2>January 30, 2023 (Mon)</h2>\n          <p>\n            It was interesting to see how Jacobian transpose relates to gradient\n            descent. However, I don't know if I fully understand the transition\n            from the equation we covered last class to the one we covered today,\n            as I don't see how subtracting the offset gives similar result. Or\n            was it suppose to mean that the gradient descent gives higher\n            accuracy because it's subtracting the offset amount of a part that\n            shouldn't be shifting? I also realized during today's class that I\n            was misunderstanding the use of rotational axis in last class when\n            it's used to cross with the distance from joint to end point (r_i).\n            I appreciate how material we cover in class build onto each other\n            instead of introducing new topic each time. This way gives me time\n            to sit with the topic we covered in class and review again during\n            the following class to strengthen understanding. Also, it\n            assimiliates how researches are done (i.e. build onto previously\n            released paper and compare & contrast).\n          </p>\n\n          <h2>February 1, 2023 (Wed)</h2>\n          <p>\n            To me, rigging and skinning always have been the 'required' steps\n            that I just had to do to get to the fun animation part. Learning\n            about RigNet and Neural Blend Shapes for rigging and skinning was\n            useful, as it seemed highly practical and time-saving. I still\n            wonder how these models were trained, specifically how blend shapes\n            are predicted. Based on my previous experience, blend shapes still\n            rely on the initial rigging and skinning that's done on the rest A\n            or T pose of the character, then set a certain pose as the end pose\n            for the blend shape. However, the Neural Blend Shapes paper seemed\n            to imply that these blend shapes can be trainned in a different\n            manner than how RigNet trains to predict where the rig would be\n            located and mesh weights would be distributed. Although my main\n            interest lies in visual effects and simulation, I think it would be\n            interesting to further look into the papers on automated rigging and\n            skinning.\n          </p>\n\n          <h2>February 6, 2023 (Mon)</h2>\n          <p>\n            Motion capture lab visit was a good review session, although since\n            it was my third time there as a class, I wasn't surprised with\n            anything new. I'm still unclear if I would use motion capture lab\n            for the final project, but I'm glad to know that it's available as\n            an option if I need to capture any motion. Learning about Arjun's\n            paper on figuring out the hand gesture by area indication on mesh\n            was highly interesting, as I haven't thought about defining a hand\n            gesture based on a contact area between the two mesh. I think in\n            general learning about what techniques are out there opens up the\n            perspective on how one can see the same problem form different\n            angles and focus.\n          </p>\n\n          <h2>February 8, 2023 (Wed)</h2>\n          <p>\n            First paper presentations today. Again, I find these paper\n            presentations really crucial and useful, as I get to have exposures\n            to various techniques out there without having to fully dive into\n            the paper and all the math. The non-Euclidean space paper was highly\n            interesting, as I've seen its applications across various video\n            games but didn't really know much about the concept and math behind\n            it. I also wouldn't have known about it since I couldn't tell that\n            the paper discussed such a topic only from the title. (i.e. I didn't\n            know such portal effect and dimension changing was called\n            non-Euclidean space...)\n          </p>\n\n          <h2>February 13, 2023 (Mon)</h2>\n          <p>\n            As also an art student, I think having a time dedicated for sharing\n            works is useful for future projects. Although it wasn't a crit\n            session for people to give ideas on how to improve on the project,\n            viewing others' works gave me a good sense of what the individual\n            strengths of this class is. It was also a session that reminded me\n            of how the artists and the developers view and operate the tools\n            differently.\n          </p>\n\n          <h2>February 15, 2023 (Wed)</h2>\n          <p>\n            I don't think I ever looked into how cloth simulation works behind\n            the scene. It was quiet a fresh idea for me to see that the cloth\n            simulation is a collection of spring phyiscs intertwined. I see how\n            this would intuitively work since cloth also has a tendancy to go\n            back to its original stable state upon stretching it out. I wonder\n            who first came up with this idea to simulate cloth.\n          </p>\n\n          <h2>February 20, 2023 (Mon)</h2>\n          <p>\n            I think cloth collision is one of the effects/simulations that can\n            convey so many different types by just tweeking a few paramenters.\n            There exits so many types and feels of fabric in this world, and I\n            think that's what makes cloth simulation both the hardest and the\n            easiest to make. As long as we make sure the cloth doesn't get\n            caught in the movement of the rig and creates an artifact, cloth\n            simulation can already look somewhat natural enough to convey the\n            idea of cloth.\n          </p>\n\n          <h2>February 22, 2023 (Wed)</h2>\n          <p>\n            Talking about different ways of collision offset/detection methods\n            reminded me of Computer Graphics light ray and particle collision\n            parts. Since we already went over and had to implement as part of\n            the Computer Graphics course, checking whether collision has\n            occurred and going forward/back in the timestep to place the object\n            at the boarder was the most straightforward idea to understand. I\n            also happened to make\n            <a href=\"https://www.instagram.com/kitetale/\">\n              a few of rigid-body collision effects in Houdini\n            </a>\n            , and I was very surprised by how accurate Houdini's code dealt with\n            collision.\n          </p>\n\n          <h2>February 27, 2023 (Mon)</h2>\n          <p>\n            Among the papers presented today, I found the cloth prediction one\n            very interesting. I learned so much through this class that Neural\n            Network has been the state of the art method for various types of\n            simulations and animation techniques. It really reminded me of how\n            AI is integrating into all industries to improve the techniques.\n            Yarn-level cloth simulation was also cool to learn about, as I\n            haven't really thought about how different patterns of weaving\n            influence how the overall cloth interacts with itself and other\n            objects. I'm not sure if it's a trend in CMU or everywhere, but I\n            also have noticed that a lot more people are now interested in the\n            algorithmic textile.\n          </p>\n\n          <h2>March 1, 2023 (Wed)</h2>\n          <p>\n            Seeing previous final projects today was so intriguing and\n            inspiring. I was not only able to understand what's expected for the\n            final project, but also guage the diversity in topics and methods\n            that I could implement for the final project. I think I want to do\n            some sort of particle simulation, probably particle simulation that\n            mimics fluid simulation. The water ripple one and rigid body contact\n            seemed very fun to play with and relatively easy to implement. Snow\n            simulation was also interesting -- I remember seeing snow simulation\n            test videos for Frozen from Art, Animation, and Technology class.\n            Perhaps I could do a wrecking ball/angry bird collision on snow-like\n            particles. I'm still not sure what I would be working on for the\n            final project, so my plan would be coming up with several ideas and\n            narrow it down to one during the meeting with professor.\n          </p>\n\n          <h2>March 13, 2023 (Mon)</h2>\n          <p>\n            I just flew in from Ithaca this morning and came straight to the\n            class. I thought I'd be missing this class, but I was able to find\n            an alternative flight that would let me be here in time for class!\n            I'm excited for my final project; I was afraid the idea I liked the\n            most (applying real-time Kinect depth mocap data to the character\n            like what Nick did before) might be out of scope for the class, but\n            I'm glad to have the professor's confirmation that it's within the\n            scope. I may have to flesh out my idea more, but I'm planning to use\n            openFrameworks to apply mocap data from Kinect's depth image to a 3d\n            character. Perhaps I can use GLSL to make the 3D character? I was\n            extremely impressed when I watched Inigo Quilez's\n            <a href=\"https://www.youtube.com/watch?v=8--5LwHRhjk&ab_channel=InigoQuilez\">\n              {\" \"}\n              \"Painting a Character with Maths\"\n            </a>{\" \"}\n            or{\" \"}\n            <a href=\"https://www.youtube.com/watch?v=Cfe5UQ-1L9Q&ab_channel=InigoQuilez\">\n              {\" \"}\n              \"Happy Jumping\"\n            </a>{\" \"}\n            animation live coding video. Perhaps I could pull some math\n            equations from these to construct my own ( simpler) character for\n            the final project. I'm thinking to have both live demo and\n            documentation video for the presentation.\n          </p>\n\n          <h2>March 15, 2023 (Wed)</h2>\n          <p>\n            Although I have decided to work with Kinect for my final project,\n            hearing about others' final project ideas and references was quiet \n            inspiring and useful. I'm planning to read more about certain papers\n            others mentioned, such as rigid body fracture based on pressure, for\n            my senior art capstone project that I'll be presenting at the senior\n            art show at Miller ICA at the end of the semester. \n            Otherwise, I'm excited to learn more about fluid simulation. It's \n            just so mindblowing to see how much graphcis technology has developed\n            over time -- Water simulation in Avater II was extremely realistic,\n            and it's always impressive to see and realize that the first 'good-looking'\n            fluid simulations only happened not so long ago. Sometimes I feel like\n            the world has invented so many algorithms and graphical techniques \n            while I was just growing up... So much has happened since 2000, if not \n            even before.\n          </p>\n\n          <h2>March 20, 2023 (Mon)</h2>\n          <p>\n            I enjoyed sharing my hard work of not only implementing interactive live webpage cloth simulation but also all the simulation engines comparisons! As I mentioned before, I'm currently working on getting a simple simulation scene done each day (hopefully..) using existing engines and upload them on instagram (@kitetale). This project helped me decide what to try for my side personal instagram simulation experimentation streak!\n          </p>\n\n          <h2>March 22, 2023 (Wed)</h2>\n          <p>\n              Today we covered more of Navier-Strokes method, which helped me a lot in understanding the paper I'm reading for my paper presenation. Since the one I chose to present is about white water and producing realistic foams & bubbles, it was referring a lot to the previous fluid simulation methods that I had no clue what each was. Now that I understand how Navier-Strokes work for bulk fluid simulation, I should go read the white water paper again to see if I can understand better what they're referring to when describing their algorithm.\n          </p>\n\n          <h2>March 27, 2023 (Mon)</h2>\n          <p>\n              More fluid algorithm was covered today, and I'm glad to learn about the lagrangian SPH method because that was the next often mentioned algorithm after Navier-Strokes in the white water paper I'm reading for the presentation. Sometimes I realize and feel shocked again and again on how everything in the world can be expressed in math.. No wonder some people argue that our world is a simulation.\n          </p>\n\n          <h2>March 29, 2023 (Wed)</h2>\n          <p>\n              I thought today's paper presentation order was really well selected.\n              People who presented after me each highlighted the aspects that the paper I presented shared \n              as the downside/limitation of the algorithm introduced in the paper. \n              For instance, my whitewater paper was written under the assumption\n              that all bubbles and foam are 'wet', meaning they cannot be stacked \n              or interact with one another other than influnecing each other's \n              position. The following person then presented the paper on 'dry', stackable foam.\n              The person after presented the water donut effects, which was omitted in my paper.\n          </p>\n\n          <h2>April 3, 2023 (Mon)</h2>\n          <p>\n              I was able to understand better of MAC grid and the P2G and G2P methods\n              now that I've read its application in the paper that I presented. Also, seeing how there are various\n              kinds, types, and movements in fluid simulation is so mindblowing -- Fluid simulation isn't just limited\n              to bulk fluid simulation, but can be narrowed down to a smaller scaled local simulation of fluid particles\n              to simulate more realistic flow and fall through varying sized objects.\n          </p>\n\n          <h2>April 5, 2023 (Wed)</h2>\n          <p>\n              Papers presented today ranged across various topics beyond cloth and fluid simulation.\n              MPM fracture paper reminded me of the solver that Houdini provided for fracture, although\n              for Houdini, I think the user had to manually set where the fractured pieces would be at in \n              what shape/size.\n\n              Deformable Objects animation by keyframing the rest shape is a good algorithm/paper \n              to keep in mind as I work on my final project. Thermomachenical Fracture for baking \n              looked very realistic, and was a good opportunity to rethink how fracture simulation\n              can be applied in different situations.\n          </p>\n          <h2>April 10, 2023 (Mon)</h2>\n          <p>\n              Papers on deformable bodies animation to portray physically realistic motion from the 90s really was impressive considering the state of the art of graphics at the time. It also specifically reminded me of this abstract animation piece that was also made for the Olympic, called <a href=\"https://vimeo.com/38017188\">Forms</a>. In this work, the artists used mocap data of althetes in their action during the game to reinterpret using abstract generative geometry. I find this progression of ways to portray athletic movements very intriguing, as it definitely lies within the realm of Computer Science and Art. (Artistic interpretation of human motion using graphics!)\n          </p>\n          <h2>April 12, 2023 (Wed)</h2>\n          <p>\n              The paper that Grace presented called <a href=\"https://tianxintao.github.io/get_up_control/\">\"Learning to Get Up</a> approached skeletal motion prediction in a new way that I haven't seen or thought of before. I often thought the target lies on the character's feet to ensure that the model is standing firmly on the floor, not floating nor penetrating it. This paper, on the other hand, sets the target to the head, predicting how the skeletal movements would be given the head should be ending up at the target point. I also thought this paper can also be used in other fields like medical emergency or any human-life related emergency situation education simulation, as the strong simulation would do the work of visualizing the optimal way for one to get up from an arbitrary fallen state (something we can't test with actual people since we can't drop people from high heights arbitrary..).\n          </p>\n\n          <h2>April 17, 2023 (Mon)</h2>\n          <p>\n              Learning more about generating skeletal animation based on input set of motion capture data was highly intriguing to me. My final project also relates to generating armature animation, and now that I'm working on it, I'm now noticing how wide this area of animating using neural network is. Although my project is more like live puppetry based on skeleton structure extracted from camera input, learning about Motion VAE (MVAE) helped me think more about various potentials I can do with skeleton data.\n          </p>\n\n          <h2>April 19, 2023 (Wed)</h2>\n          <p>\n              Papers presented today introduced other ways to track and generate skeletal animation based on mocap data. The paper on VR headset/controller three point tracking was surprisingly more accurate in terms of motion prediction given that it only takes one or three tracking points (headset, two hand-held controllers). \n\n              The crowd simulation paper made me think how crowd simulation also involves movement trends algorithm (which the presented paper introduced). Previously, I've seen papers that address how one can diversify the individual crowd motion animation by interpolating and merging multiple mocap data. Perhaps games like Hitman and animation films do use both aspects to diversify both movement trend and individual animations.\n          </p>\n          \n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default technicalanimation;\n","// extracted by mini-css-extract-plugin\nexport var center = \"ResumePage-module--center--9b0dd\";\nexport var centerButton = \"ResumePage-module--centerButton--df016\";\nexport var centerTitle = \"ResumePage-module--centerTitle--bbb03\";\nexport var content = \"ResumePage-module--content--dfefc\";\nexport var content2 = \"ResumePage-module--content2--e4fd6\";\nexport var footDescrip = \"ResumePage-module--footDescrip--5a6f4\";\nexport var footer = \"ResumePage-module--footer--ef519\";\nexport var overall = \"ResumePage-module--overall--a999b\";\nexport var resumeStyle = \"ResumePage-module--resumeStyle--64bc2\";\nexport var title = \"ResumePage-module--title--acc5f\";\nexport var title3 = \"ResumePage-module--title3--2ba8f\";"],"names":["rel","type","href","favicon","className","overall","content2","center","centerButton","centerTitle","content","footDescrip","footer","resumeStyle","title"],"sourceRoot":""}